{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573db1e-b3b0-412f-9f50-edb606721501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as rd\n",
    "\n",
    "class Seq2Seq_Model():\n",
    "    def __init__(self, nnet_size, n_layer, feature_dim, embedding_size, lambda_r, wordkeytrans, mode, max_grad_norm, use_attention, beam_search, beam_size, max_encoder_steps, max_decoder_steps):\n",
    "        tf.set_random_seed(2000)\n",
    "        np.random.seed(2000)\n",
    "        rd.seed(2000)\n",
    "\n",
    "        self.nnet_size = nnet_size\n",
    "        self.n_layer = n_layer\n",
    "        self.feature_dim = feature_dim\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lambda_r = lambda_r\n",
    "        self.wordkeytrans = wordkeytrans\n",
    "        self.mode = mode\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        self.use_attention = use_attention\n",
    "        self.beam_search = beam_search\n",
    "        self.beam_size = beam_size\n",
    "        self.max_encoder_steps = max_encoder_steps\n",
    "        self.max_decoder_steps = max_decoder_steps\n",
    "\n",
    "        self.vocab_size = len(self.wordkeytrans)\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def _create_rnn_cell(self):\n",
    "        def single_rnn_cell():\n",
    "            single_cell = tf.contrib.rnn.GRUCell(self.nnet_size)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(single_cell, output_keep_prob=self.keep_prob_placeholder, seed=2020)\n",
    "            return cell\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([single_rnn_cell() for _ in range(self.n_layer)])\n",
    "        return cell\n",
    "\n",
    "    def build_model(self):\n",
    "        tf.set_random_seed(2000)\n",
    "        np.random.seed(2000)\n",
    "        rd.seed(2000)\n",
    "\n",
    "        print ('Building model...')\n",
    "        self.encoder_inputs = tf.placeholder(tf.float32, [None, None, None], name='encoder_inputs')\n",
    "        self.encoder_inputs_length = tf.placeholder(tf.int32, [None], name='encoder_inputs_length')\n",
    "\n",
    "        self.batch_size = tf.placeholder(tf.int32, [], name='batch_size')\n",
    "        self.keep_prob_placeholder = tf.placeholder(tf.float32, name='keep_prob_placeholder')\n",
    "\n",
    "        self.decoder_targets = tf.placeholder(tf.int32, [None, None], name='decoder_targets')\n",
    "        self.decoder_targets_length = tf.placeholder(tf.int32, [None], name='decoder_targets_length')\n",
    "\n",
    "        self.max_target_sequence_length = tf.reduce_max(self.decoder_targets_length, name='max_target_len')\n",
    "        self.mask = tf.sequence_mask(self.decoder_targets_length, self.max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "        ######################Define model's encoder #############################\n",
    "        with tf.variable_scope('encoder', reuse=tf.AUTO_REUSE):\n",
    "            # Encoder embedding.\n",
    "            encoder_inputs_flatten = tf.reshape(self.encoder_inputs, [-1, self.feature_dim])\n",
    "            encoder_inputs_embedded = tf.layers.dense(encoder_inputs_flatten, self.embedding_size, use_bias=True)\n",
    "            encoder_inputs_embedded = tf.reshape(encoder_inputs_embedded, [self.batch_size, self.max_encoder_steps, self.nnet_size])\n",
    "\n",
    "            # Build RNN cell\n",
    "            encoder_cell = self._create_rnn_cell()\n",
    "\n",
    "            # Run Dynamic RNN\n",
    "            encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "                encoder_cell, encoder_inputs_embedded, \n",
    "                sequence_length=self.encoder_inputs_length, \n",
    "                dtype=tf.float32)\n",
    "\n",
    "               \n",
    "        with tf.variable_scope('decoder', reuse=tf.AUTO_REUSE):\n",
    "            encoder_inputs_length = self.encoder_inputs_length\n",
    "\n",
    "            if self.beam_search:\n",
    "                \n",
    "                print(\"Using beamsearch decoding...\")\n",
    "                encoder_outputs = tf.contrib.seq2seq.tile_batch(encoder_outputs, multiplier=self.beam_size)\n",
    "                encoder_state = tf.contrib.framework.nest.map_structure(lambda s: tf.contrib.seq2seq.tile_batch(s, self.beam_size), encoder_state)\n",
    "                encoder_inputs_length = tf.contrib.seq2seq.tile_batch(self.encoder_inputs_length, multiplier=self.beam_size)\n",
    "\n",
    "            #If beam_seach is used, batch_size = self.batch_size * self.beam_size. Because it has been copied once before\n",
    "            batch_size = self.batch_size if not self.beam_search else self.batch_size * self.beam_size\n",
    "\n",
    "            # A dense matrix to turn the top hidden states to logit vectors of dimension V.\n",
    "            projection_layer = tf.layers.Dense(units=self.vocab_size, kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1, seed=2020))\n",
    "            \n",
    "            # Decoder embedding\n",
    "            embedding_decoder = tf.Variable(tf.random_uniform([self.vocab_size, self.nnet_size], -0.1, 0.1, seed=2020), name='embedding_decoder')\n",
    "\n",
    "            decoder_cell = self._create_rnn_cell()\n",
    "\n",
    "            if self.use_attention:\n",
    "                #Define the attention mechanism to be used\n",
    "                attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                    num_units=self.nnet_size, \n",
    "                    memory=encoder_outputs, \n",
    "                    normalize=True,\n",
    "                    memory_sequence_length=encoder_inputs_length)\n",
    "\n",
    "                #Define the LSTMCell used in the decoder stage\n",
    "                decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                    cell=decoder_cell, \n",
    "                    attention_mechanism=attention_mechanism, \n",
    "                    attention_layer_size=self.nnet_size, \n",
    "                    name='Attention_Wrapper')\n",
    "\n",
    "                #Define the initialization state of the decoder stage, directly use the last hidden layer state of the encoder stage for assignment\n",
    "                decoder_initial_state = decoder_cell.zero_state(batch_size=batch_size, dtype=tf.float32).clone(cell_state=encoder_state)\n",
    "            else:\n",
    "                decoder_initial_state = encoder_state\n",
    "\n",
    "            output_layer = tf.layers.Dense(self.vocab_size, kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1, seed=2020))\n",
    "\n",
    "           \n",
    "            ending = tf.strided_slice(self.decoder_targets, [0, 0], [self.batch_size, -1], [1, 1])\n",
    "            decoder_inputs = tf.concat([tf.fill([self.batch_size, 1], self.wordkeytrans['<bos>']), ending], 1)\n",
    "            \n",
    "            decoder_inputs_embedded = tf.nn.embedding_lookup(embedding_decoder, decoder_inputs)\n",
    "\n",
    "            # Helper\n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                inputs=decoder_inputs_embedded, \n",
    "                sequence_length=self.decoder_targets_length, \n",
    "                time_major=False, name='training_helper')\n",
    "            # Decoder\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell=decoder_cell, helper=training_helper, \n",
    "                initial_state=decoder_initial_state, \n",
    "                output_layer=output_layer)\n",
    "            \n",
    "            \n",
    "            decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=training_decoder, impute_finished=True, maximum_iterations=self.max_target_sequence_length)\n",
    "\n",
    "            # Calculate the loss and gradient according to the output, and define the AdamOptimizer and train_op to be updated\n",
    "            self.decoder_logits_train = tf.identity(decoder_outputs.rnn_output)\n",
    "            self.decoder_predict_train = tf.argmax(self.decoder_logits_train, axis=-1, name='decoder_pred_train')\n",
    "            self.loss = tf.contrib.seq2seq.sequence_loss(\n",
    "                logits=self.decoder_logits_train, \n",
    "                targets=self.decoder_targets, \n",
    "                weights=self.mask)\n",
    "\n",
    "            tf.summary.scalar('loss', self.loss)\n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer(self.lambda_r)\n",
    "            trainable_params = tf.trainable_variables()\n",
    "            gradients = tf.gradients(self.loss, trainable_params)\n",
    "            clip_gradients, _ = tf.clip_by_global_norm(gradients, self.max_grad_norm)\n",
    "            self.train_op = optimizer.apply_gradients(zip(clip_gradients, trainable_params))\n",
    "\n",
    "           \n",
    "            start_tokens = tf.ones([self.batch_size, ], tf.int32) * self.wordkeytrans['<bos>']\n",
    "            end_token = self.wordkeytrans['<eos>']\n",
    "            \n",
    "            \n",
    "            if self.beam_search:\n",
    "                inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                    cell=decoder_cell, \n",
    "                    embedding=embedding_decoder,\n",
    "                    start_tokens=start_tokens, \n",
    "                    end_token=end_token,\n",
    "                    initial_state=decoder_initial_state,\n",
    "                    beam_width=self.beam_size,\n",
    "                    output_layer=output_layer)\n",
    "            else:\n",
    "                # Helper\n",
    "                inference_decoding_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "                    embedding=embedding_decoder, \n",
    "                    start_tokens=start_tokens, \n",
    "                    end_token=end_token)\n",
    "                # Decoder\n",
    "                inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    cell=decoder_cell, \n",
    "                    helper=inference_decoding_helper, \n",
    "                    initial_state=decoder_initial_state, \n",
    "                    output_layer=output_layer)\n",
    "\n",
    "          \n",
    "            inference_decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder=inference_decoder, maximum_iterations=self.max_decoder_steps)\n",
    "\n",
    "            if self.beam_search:\n",
    "                self.decoder_predict_decode = inference_decoder_outputs.predicted_ids\n",
    "                self.decoder_predict_logits = inference_decoder_outputs.beam_search_decoder_output\n",
    "            else:\n",
    "                self.decoder_predict_decode = tf.expand_dims(inference_decoder_outputs.sample_id, -1)\n",
    "                self.decoder_predict_logits = inference_decoder_outputs.rnn_output\n",
    "\n",
    "        self.saver = tf.train.Saver(tf.global_variables(), max_to_keep=10)\n",
    "\n",
    "    def train(self, sess, encoder_inputs, encoder_inputs_length, decoder_targets, decoder_targets_length):\n",
    "        feed_dict = {self.encoder_inputs: encoder_inputs,\n",
    "                      self.encoder_inputs_length: encoder_inputs_length,\n",
    "                      self.decoder_targets: decoder_targets,\n",
    "                      self.decoder_targets_length: decoder_targets_length,\n",
    "                      self.keep_prob_placeholder: 0.5,\n",
    "                      self.batch_size: len(encoder_inputs)}\n",
    "        _, loss, summary = sess.run([self.train_op, self.loss, self.summary_op], feed_dict=feed_dict)\n",
    "        return loss, summary\n",
    "\n",
    "    def eval(self, sess, encoder_inputs, encoder_inputs_length, decoder_targets, decoder_targets_length):\n",
    "        feed_dict = {self.encoder_inputs: encoder_inputs,\n",
    "                      self.encoder_inputs_length: encoder_inputs_length,\n",
    "                      self.decoder_targets: decoder_targets,\n",
    "                      self.decoder_targets_length: decoder_targets_length,\n",
    "                      self.keep_prob_placeholder: 1.0,\n",
    "                      self.batch_size: len(encoder_inputs)}\n",
    "        loss, summary = sess.run([self.loss, self.summary_op], feed_dict=feed_dict)\n",
    "        return loss, summary\n",
    "\n",
    "    def infer(self, sess, encoder_inputs, encoder_inputs_length):\n",
    "        feed_dict = {self.encoder_inputs: encoder_inputs,\n",
    "                      self.encoder_inputs_length: encoder_inputs_length,\n",
    "                      self.keep_prob_placeholder: 1.0,\n",
    "                      self.batch_size: len(encoder_inputs)}\n",
    "        predict, logits = sess.run([self.decoder_predict_decode, self.decoder_predict_logits], feed_dict=feed_dict)\n",
    "        return predict, logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
